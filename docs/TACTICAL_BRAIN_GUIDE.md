# üß† Guide Complet du Tactical Brain

## Vue d'ensemble

Le **TacticalBrain** est le cerveau strat√©gique du syst√®me Matriarche. Il utilise un LLM (TinyLlama-1.1B) quantifi√© en 4-bit pour g√©n√©rer des plans tactiques intelligents bas√©s sur les donn√©es de reconnaissance.

---

## Architecture

### Composants

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         TacticalBrain (LLM)             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  TinyLlama-1.1B-Chat (4-bit)    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  M√©moire: ~800MB                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ              ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ    Analyse Intel Reports         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ              ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  G√©n√©ration Plan Tactique        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  (Target, Action, Reasoning)     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         FeedbackLoop                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Historique Succ√®s/√âchecs        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Patterns de Failure             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Recommandations                 ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Utilisation

### Initialisation

```python
from matriarche.intelligence.tactical_brain import TacticalBrain

# Configuration
config = {
    'use_4bit_quantization': True,  # Quantification 4-bit pour √©conomie RAM
    'max_memory_gb': 0.8,            # Limite m√©moire
    'auto_load': False               # Chargement manuel (recommand√©)
}

# Cr√©ation
brain = TacticalBrain(config)

# Chargement du mod√®le
if brain._load_model():
    print("‚úì Mod√®le charg√© avec succ√®s")
```

### G√©n√©ration de Plans Tactiques

```python
# Donn√©es de reconnaissance (exemple)
intel_reports = [
    {
        'knowledge': {
            'systems': {
                '192.168.1.100': {
                    'ports': [22, 80, 443],
                    'os': ['Linux'],
                    'hostname': 'webserver01'
                }
            },
            'credentials': []
        },
        'discoveries': [
            {
                'type': 'system',
                'vulnerabilities': [
                    {
                        'cve_id': 'CVE-2023-1234',
                        'cvss_score': 9.8,
                        'description': 'Critical RCE vulnerability in Apache'
                    }
                ]
            }
        ]
    }
]

# G√©n√©ration du plan
plan = brain.analyze_and_plan(intel_reports, feedback_context="")

# R√©sultat
print(f"Target: {plan['target']}")
print(f"Action: {plan['action']}")
print(f"Reasoning: {plan['reasoning']}")
print(f"Priority: {plan['priority']}")
print(f"Estimated Success: {plan['estimated_success']}")
```

### R√©sultat Exemple

```json
{
  "target": "192.168.1.100",
  "action": "exploit",
  "reasoning": "Target has critical RCE vulnerability (CVE-2023-1234) with CVSS 9.8. Apache service detected on port 80/443. High probability of successful exploitation.",
  "priority": "high",
  "estimated_success": 0.85,
  "generated_at": 1703001234.56,
  "model_version": "TinyLlama-1.1B-Chat-v1.0",
  "context": {
    "reports_analyzed": 1,
    "total_systems": 1,
    "total_vulnerabilities": 1
  }
}
```

---

## FeedbackLoop

### Enregistrement de R√©sultats

```python
from matriarche.intelligence.feedback_loop import FeedbackLoop

feedback = FeedbackLoop(storage_path='/tmp/matriarche_feedback')

# Enregistrement d'un succ√®s
feedback.record_operation(
    plan={'action': 'exploit', 'target': '192.168.1.100'},
    success=True,
    result={'output': 'Shell obtained', 'session_id': 123}
)

# Enregistrement d'un √©chec
feedback.record_operation(
    plan={'action': 'exploit', 'target': '192.168.1.101'},
    success=False,
    result={'error': 'Target patched against exploit'}
)
```

### Contexte de Feedback

```python
# G√©n√©ration de contexte pour le LLM
context = feedback.get_feedback_context(max_failures=5)

# Utilisation dans g√©n√©ration de plan
plan = brain.analyze_and_plan(intel_reports, feedback_context=context)
```

### Recommandations

```python
# √âvaluation d'un plan propos√©
recommendation = feedback.get_recommendation(proposed_plan)

if not recommendation['recommended']:
    print(f"‚ö†Ô∏è  Plan non recommand√©: {recommendation['reason']}")
    
    if recommendation.get('alternative_suggested'):
        alt = recommendation['alternative']
        print(f"Alternative sugg√©r√©e: {alt['action']} - {alt['reason']}")
```

---

## Int√©gration avec MatriarchBrain

### Cycle de R√©veil

Le TacticalBrain est automatiquement appel√© lors des cycles de r√©veil de la Matriarche:

```python
# Dans MatriarchBrain._wake_cycle()

# Phase 2b: G√©n√©ration de plan tactique avec LLM
if self.tactical_brain and len(intel) > 0:
    print(f"[{self.node_id}] Generating tactical plan with LLM...")
    tactical_plan = self._generate_tactical_plan(intel)
    
    if tactical_plan:
        self._process_tactical_plan(tactical_plan)
```

### Rapport de R√©sultat

```python
# Apr√®s ex√©cution d'une mission
matriarche.report_mission_result(
    mission_id='mission_123',
    success=True,
    result={'output': 'Objective achieved'}
)
```

---

## Optimisations M√©moire

### Quantification 4-bit

Le mod√®le utilise la quantification NF4 (NormalFloat4) pour r√©duire l'empreinte m√©moire:

```python
from transformers import BitsAndBytesConfig

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True,
    bnb_4bit_compute_dtype=torch.float16
)
```

**Gains:**
- Mod√®le original: ~4.4 GB
- Mod√®le quantifi√©: ~800 MB
- Perte de qualit√©: <5%

### Lazy Loading

Le mod√®le n'est charg√© qu'√† la demande:

```python
config = {
    'auto_load': False  # Pas de chargement automatique
}

brain = TacticalBrain(config)

# Chargement manuel quand n√©cessaire
if needed:
    brain._load_model()

# D√©chargement apr√®s utilisation
brain.unload_model()
```

### √âconomie M√©moire

```python
# Pas de gradients (mode inf√©rence uniquement)
with torch.no_grad():
    outputs = model.generate(...)

# Nettoyage cache CUDA
if torch.cuda.is_available():
    torch.cuda.empty_cache()
```

---

## Param√®tres de G√©n√©ration

### Configuration

```python
# Dans _generate()
outputs = model.generate(
    **inputs,
    max_new_tokens=500,           # Longueur max de r√©ponse
    do_sample=True,               # √âchantillonnage stochastique
    temperature=0.7,              # Contr√¥le cr√©ativit√© (0.1-1.0)
    top_p=0.9,                    # Nucleus sampling
    top_k=50,                     # Top-K sampling
    pad_token_id=tokenizer.eos_token_id
)
```

### Tuning

- **temperature**: 
  - 0.1-0.3: R√©ponses d√©terministes
  - 0.5-0.7: √âquilibr√© (recommand√©)
  - 0.8-1.0: Cr√©atif/impr√©visible

- **top_p**: Probabilit√© cumulative
  - 0.9: Recommand√©
  - 1.0: Aucun filtrage

- **top_k**: Nombre de tokens consid√©r√©s
  - 50: Recommand√©
  - 0: D√©sactiv√©

---

## Prompt Engineering

### Structure du Prompt

```
<|system|>
You are a tactical cybersecurity analyst.
</|system|>

<|user|>
RECONNAISSANCE DATA:
- Systems discovered: X
- Vulnerabilities found: Y
- Credentials obtained: Z

DETAILED FINDINGS:
[...]

PREVIOUS FAILURES TO AVOID:
[...]

TASK:
Generate a tactical plan with:
1. TARGET
2. ACTION
3. REASONING
4. PRIORITY

Format: JSON
</|user|>

<|assistant|>
[R√©ponse du mod√®le]
```

### Optimisations

1. **Concision**: Prompt limit√© √† 1500 tokens
2. **Structure**: Format JSON explicite
3. **Contexte**: √âchecs r√©cents inclus
4. **Priorit√©s**: Top 3 syst√®mes/vulns seulement

---

## Statistiques & Monitoring

### R√©cup√©ration des Stats

```python
stats = brain.get_statistics()

print(f"Model loaded: {stats['model_loaded']}")
print(f"Generations: {stats['generation_count']}")
print(f"Memory used: {stats['memory_used_gb']:.2f} GB")
print(f"Device: {stats['device']}")
```

### Historique

```python
# Historique des g√©n√©rations (limit√© aux 20 derni√®res)
for entry in brain.generation_history[-5:]:
    print(f"Timestamp: {entry['timestamp']}")
    print(f"Reports: {entry['reports_count']}")
    print(f"Plan: {entry['plan']['action']} on {entry['plan']['target']}")
```

---

## D√©pannage

### Probl√®mes Communs

1. **OutOfMemoryError**
   - R√©duire `max_new_tokens`
   - V√©rifier `low_cpu_mem_usage=True`
   - Augmenter la RAM disponible

2. **Slow Generation**
   - Normal pour CPU (30-60s par plan)
   - Utiliser GPU si disponible
   - R√©duire la longueur du prompt

3. **Poor Quality Plans**
   - Ajuster `temperature` (0.5-0.7)
   - Am√©liorer le prompt
   - Fournir plus de contexte

### Debug Mode

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Active les logs d√©taill√©s
brain = TacticalBrain(config)
plan = brain.analyze_and_plan(intel, feedback_context)
```

---

## Exemples Avanc√©s

### Fine-tuning (LoRA)

```python
from peft import PeftModel

# Chargement du mod√®le de base
base_model = AutoModelForCausalLM.from_pretrained(...)

# Chargement de l'adaptateur LoRA
model = PeftModel.from_pretrained(base_model, "./lora_adapters")

# Utilisation dans TacticalBrain
brain.model = model
```

### Plans Multi-√âtapes

```python
# Plan initial
plan = brain.analyze_and_plan(intel_initial)

# Ex√©cution phase 1
result_phase1 = execute_plan(plan)

# G√©n√©ration phase 2 bas√©e sur r√©sultats
intel_phase2 = collect_new_intel()
plan_phase2 = brain.analyze_and_plan(intel_phase2, 
                                     feedback_context=result_phase1)
```

---

## Performance

### Benchmarks (CPU Intel i7)

- **Chargement mod√®le**: 5-10s
- **G√©n√©ration plan**: 30-60s
- **M√©moire utilis√©e**: ~800MB
- **Pr√©cision**: 85-90% vs humain

### Optimisations Futures

1. Quantification INT8 (plus rapide)
2. Distillation du mod√®le
3. Caching des plans similaires
4. Fine-tuning sp√©cialis√©

---

## R√©f√©rences

- [TinyLlama GitHub](https://github.com/jzhang38/TinyLlama)
- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [BitsAndBytes](https://github.com/TimDettmers/bitsandbytes)
- [PEFT (LoRA)](https://github.com/huggingface/peft)

---

**Auteur**: AllForOne Matriarche System  
**Version**: 2.0.0  
**Date**: 2025-12-17
